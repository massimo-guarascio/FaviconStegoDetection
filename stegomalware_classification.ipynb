{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from stego_classifier_extended import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utils\n",
    "\n",
    "#convert to binary\n",
    "def messageToBinary(message):\n",
    "  if type(message) == str:\n",
    "    return ''.join([ format(ord(i), \"08b\") for i in message ])\n",
    "  elif type(message) == bytes or type(message) == np.ndarray:\n",
    "    return [ format(i, \"08b\") for i in message ]\n",
    "  elif type(message) == int or type(message) == np.uint8:\n",
    "    return format(message, \"08b\")\n",
    "  else:\n",
    "    raise TypeError(\"Input type not supported\")\n",
    "  \n",
    "#extract k lsb for each channel\n",
    "def extract_k_lsb_features(data, k=4):\n",
    "    lsb_training = []\n",
    "    for img in data:\n",
    "        binary_data = []\n",
    "        for values in img:\n",
    "            for pixel in values:\n",
    "                r, g, b = messageToBinary(pixel)\n",
    "                for i in range(1,k+1):\n",
    "                    binary_data.append(int(r[-1-i+1]))  # extracting data from the least significant bit of red pixel\n",
    "                    binary_data.append(int(g[-1-i+1]))  # extracting data from the least significant bit of green pixel\n",
    "                    binary_data.append(int(b[-1-i+1]))  # extracting data from the least significant bit of blue pixel\n",
    "                # split by 8-bits\n",
    "\n",
    "        lsb_training.append(np.array(binary_data))\n",
    "        \n",
    "\n",
    "    return np.array(lsb_training)\n",
    "\n",
    "# load images in the image_path\n",
    "def load_images(image_path):\n",
    "    images = []\n",
    "    for f_name in sorted(glob.glob(image_path + '/*.png')):\n",
    "        img = np.asarray(Image.open(f_name).convert('RGB'))\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "#convert an image into array\n",
    "def convert_np_array(vector):\n",
    "    result = []\n",
    "    for v in vector:\n",
    "        result.append(v)\n",
    "    return np.array(result)\n",
    "\n",
    "#laod data\n",
    "def load_data(main_data_folder, usage_folder_name, legit_folder_name, stego_folder_names):\n",
    "    \n",
    "    data_path = os.path.join(main_data_folder, usage_folder_name)\n",
    "    data_to_load = []\n",
    "    num_stego_images_for_class = []\n",
    "    data_to_load.append(convert_np_array(load_images(os.path.join(data_path,legit_folder_name))))\n",
    "    for stego_folder_name in stego_folder_names:\n",
    "        stego_images = convert_np_array(load_images(os.path.join(data_path,stego_folder_name)))\n",
    "        num_stego_images_for_class.append(stego_images.shape[0])\n",
    "        data_to_load.append(stego_images)\n",
    "\n",
    "    num_legit_images = data_to_load[0].shape[0]\n",
    "    print(\"#legit images\", data_to_load[0].shape[0])\n",
    "    print(\"#stego images\", num_stego_images_for_class)\n",
    "\n",
    "    data_to_load = np.concatenate(data_to_load)\n",
    "    print(\"data shape: \", data_to_load.shape)\n",
    "\n",
    "    print(\"done\")\n",
    "    \n",
    "    return data_to_load, num_legit_images, np.array(num_stego_images_for_class)\n",
    "\n",
    "#create target variable with labels\n",
    "def create_target_labels(legits, stego_type_number):\n",
    "    target = []\n",
    "    i = 0\n",
    "    target.append(np.zeros(legits, dtype=np.int8))\n",
    "    for current_stego in stego_type_number:\n",
    "        target.append(np.ones(current_stego, dtype=np.int8)+i)\n",
    "        i=i+1\n",
    "    return np.concatenate(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters ---------------------------\n",
    "\n",
    "data_folder = \"/ImageDirectory/dataset\"\n",
    "legit_folder = 'legit'\n",
    "stego_folders = ['LSB_stego_php','LSB_stego_url']\n",
    "cwd = './'\n",
    "model_space = 'output/models-separate'\n",
    "seed = 230782\n",
    "k_lsb = 3\n",
    "#------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stego Malware Classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#legit images 29999\n",
      "#stego images [29999, 119996]\n",
      "data shape:  (179994, 32, 32, 3)\n",
      "done\n",
      "#training shape, neg, pos:  (179994, 32, 32, 3) 29999 149995\n",
      "#num classes:  3\n",
      "#num examples for class:\n",
      "[[     0  29999]\n",
      " [     1  29999]\n",
      " [     2 119996]]\n",
      "Apply OHE\n",
      "training set ready\n"
     ]
    }
   ],
   "source": [
    "#loading training set\n",
    "training_set, num_training_legit, num_training_stego_for_class  = load_data(data_folder, \"training\", legit_folder, stego_folders)\n",
    "num_training_stego = np.sum(num_training_stego_for_class)\n",
    "num_targets = len(num_training_stego_for_class)+1\n",
    "print(\"#training shape, neg, pos: \", training_set.shape, num_training_legit, num_training_stego)\n",
    "print(\"#num classes: \", num_targets)\n",
    "\n",
    "#lsb extraction\n",
    "training_set = extract_k_lsb_features(training_set, k_lsb)\n",
    "\n",
    "#create target\n",
    "y_train = create_target_labels(num_training_legit, num_training_stego_for_class) \n",
    "print(\"#num examples for class:\")\n",
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "print(\"Apply OHE\")\n",
    "ohe_processer = OneHotEncoder(handle_unknown='ignore')\n",
    "ohe_y_train = ohe_processer.fit_transform(np.reshape(y_train,(-1,1))).toarray()\n",
    "print(\"training set ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#legit images 15000\n",
      "#stego images [15000, 60000]\n",
      "data shape:  (90000, 32, 32, 3)\n",
      "done\n",
      "#validation shape, neg, pos:  (90000, 32, 32, 3) 15000 75000\n",
      "#num examples for class:\n",
      "[[    0 15000]\n",
      " [    1 15000]\n",
      " [    2 60000]]\n",
      "Apply OHE\n",
      "validation set ready\n"
     ]
    }
   ],
   "source": [
    "#loading validation set\n",
    "validation, num_val_legit, num_val_stego_for_class  = load_data(data_folder, \"validation\", legit_folder, stego_folders)\n",
    "num_val_stego = np.sum(num_val_stego_for_class)\n",
    "print(\"#validation shape, neg, pos: \", validation.shape, num_val_legit, num_val_stego)\n",
    "\n",
    "#lsb extraction\n",
    "validation = extract_k_lsb_features(validation, k_lsb)\n",
    "\n",
    "#create target\n",
    "y_val = create_target_labels(num_val_legit, num_val_stego_for_class)\n",
    "print(\"#num examples for class:\")\n",
    "(unique, counts) = np.unique(y_val, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "print(\"Apply OHE\")\n",
    "ohe_y_val = ohe_processer.transform(np.reshape(y_val,(-1,1))).toarray()\n",
    "print(\"validation set ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model path:  ./output/models-separate/best_model_stego_classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 22:34:49.745702: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#init classifier\n",
    "classifier = StegoClassifierExtended(training_set.shape[1], num_targets)\n",
    "\n",
    "#compile classifier\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer=RMSprop(learning_rate=1e-3), metrics=['accuracy'])\n",
    "\n",
    "#init callbacks\n",
    "model_path = os.path.join(cwd, model_space, 'best_model_stego_classification')\n",
    "print(\"best model path: \", model_path)\n",
    "check = ModelCheckpoint(model_path, monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "704/704 [==============================] - 28s 38ms/step - loss: 0.0283 - accuracy: 0.9917 - val_loss: 0.0167 - val_accuracy: 0.9933\n",
      "Epoch 2/20\n",
      "704/704 [==============================] - 21s 29ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 7.2584e-04 - val_accuracy: 0.9998\n",
      "Epoch 3/20\n",
      "704/704 [==============================] - 21s 30ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 2.7799e-04 - val_accuracy: 0.9999\n",
      "Epoch 4/20\n",
      "704/704 [==============================] - 21s 30ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
      "Epoch 5/20\n",
      "704/704 [==============================] - 22s 31ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.1617 - val_accuracy: 0.9629\n",
      "Epoch 6/20\n",
      "704/704 [==============================] - 23s 32ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 9.8229e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 9.8890e-04 - accuracy: 0.9998 - val_loss: 4.3731e-04 - val_accuracy: 0.9998\n",
      "Epoch 8/20\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 8.9155e-04 - accuracy: 0.9999 - val_loss: 2.0468e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 6.3925e-04 - accuracy: 0.9999 - val_loss: 5.6281e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "704/704 [==============================] - 23s 32ms/step - loss: 5.2696e-04 - accuracy: 0.9999 - val_loss: 2.2250e-05 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "704/704 [==============================] - 23s 32ms/step - loss: 7.5397e-04 - accuracy: 0.9999 - val_loss: 3.6054e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 6.6334e-04 - accuracy: 0.9999 - val_loss: 1.1184e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "704/704 [==============================] - 23s 32ms/step - loss: 6.6373e-04 - accuracy: 0.9999 - val_loss: 1.5991e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "704/704 [==============================] - 23s 32ms/step - loss: 3.6602e-04 - accuracy: 0.9999 - val_loss: 3.5070e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "704/704 [==============================] - 23s 32ms/step - loss: 8.4157e-04 - accuracy: 0.9999 - val_loss: 2.8692e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "704/704 [==============================] - 22s 32ms/step - loss: 5.7919e-04 - accuracy: 0.9999 - val_loss: 3.6095e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "704/704 [==============================] - 22s 32ms/step - loss: 6.8991e-04 - accuracy: 0.9999 - val_loss: 6.5042e-06 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "704/704 [==============================] - 22s 32ms/step - loss: 3.1537e-04 - accuracy: 0.9999 - val_loss: 8.9367e-07 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "704/704 [==============================] - 23s 33ms/step - loss: 4.3199e-04 - accuracy: 0.9999 - val_loss: 5.9428e-07 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "704/704 [==============================] - 22s 32ms/step - loss: 2.9216e-04 - accuracy: 1.0000 - val_loss: 5.9484e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x161410f10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#training model\n",
    "classifier.fit(training_set, ohe_y_train, batch_size=256, epochs=20, validation_data=(validation, ohe_y_val), callbacks=[check], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x16146d050>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reload best model\n",
    "classifier.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#legit images 15001\n",
      "#stego images [15001, 60004]\n",
      "data shape:  (90006, 32, 32, 3)\n",
      "done\n",
      "#test shape, neg, pos:  (90006, 32, 32, 3) 15001 75005\n",
      "#num examples for class:\n",
      "[[    0 15001]\n",
      " [    1 15001]\n",
      " [    2 60004]]\n",
      "Apply OHE\n",
      "test set ready\n"
     ]
    }
   ],
   "source": [
    "#loading test set\n",
    "test, num_test_legit, num_test_stego_for_class  = load_data(data_folder, \"test\", legit_folder, stego_folders)\n",
    "num_test_stego = np.sum(num_test_stego_for_class)\n",
    "print(\"#test shape, neg, pos: \", test.shape, num_test_legit, num_test_stego)\n",
    "\n",
    "#lsb extraction\n",
    "test = extract_k_lsb_features(test, k_lsb)\n",
    "\n",
    "#create target\n",
    "y_test = create_target_labels(num_test_legit, num_test_stego_for_class)\n",
    "print(\"#num examples for class:\")\n",
    "(unique, counts) = np.unique(y_test, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "print(\"Apply OHE\")\n",
    "ohe_y_test = ohe_processer.transform(np.reshape(y_test,(-1,1))).toarray()\n",
    "print(\"test set ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc;prec;rec;f1;auc;auc-pr\n",
      "1.0;1.0;1.0;1.0;1.0;1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_score = classifier.predict(test)\n",
    "\n",
    "y_pred_label = np.around(y_pred_score, 0)\n",
    "\n",
    "report_map = classification_report(y_test, np.argmax(y_pred_score, axis=1), output_dict=True)\n",
    "\n",
    "#acc_score = accuracy_score(ohe_y_test, y_pred_label)\n",
    "acc_score = accuracy_score(y_test, np.argmax(y_pred_score, axis=1))\n",
    "\n",
    "auc_score = roc_auc_score(ohe_y_test, y_pred_score, multi_class=\"ovr\", average=\"macro\")\n",
    "\n",
    "auc_score_pr = average_precision_score(ohe_y_test, y_pred_score)\n",
    "\n",
    "result = str(acc_score)+\";\"+str(report_map['macro avg']['precision']) + \";\" + str(\n",
    "        report_map['macro avg']['recall']) + \";\" + str(report_map['macro avg']['f1-score']) + \";\" + str(\n",
    "        auc_score)  + \";\" + str(auc_score_pr)\n",
    " \n",
    "print(\"acc;prec;rec;f1;auc;auc-pr\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#legit images 15001\n",
      "#stego images [15001, 60004]\n",
      "data shape:  (90006, 32, 32, 3)\n",
      "done\n",
      "#test unseen shape, neg, pos:  (90006, 32, 32, 3) 15001 75005\n",
      "#num examples for class:\n",
      "[[    0 15001]\n",
      " [    1 15001]\n",
      " [    2 60004]]\n",
      "Apply OHE\n",
      "test set unseen ready\n"
     ]
    }
   ],
   "source": [
    "#loading test set unseen\n",
    "test_unseen, num_test_unseen_legit, num_test_unseen_stego_for_class  = load_data(data_folder, \"test_unseen\", legit_folder, stego_folders)\n",
    "num_test_unseen_stego = np.sum(num_test_unseen_stego_for_class)\n",
    "print(\"#test unseen shape, neg, pos: \", test_unseen.shape, num_test_unseen_legit, num_test_unseen_stego)\n",
    "\n",
    "#lsb extraction\n",
    "test_unseen = extract_k_lsb_features(test_unseen, k_lsb)\n",
    "\n",
    "#create target\n",
    "y_test_unseen = create_target_labels(num_test_unseen_legit, num_test_unseen_stego_for_class)\n",
    "print(\"#num examples for class:\")\n",
    "(unique, counts) = np.unique(y_test_unseen, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)\n",
    "print(\"Apply OHE\")\n",
    "ohe_y_test_unseen = ohe_processer.transform(np.reshape(y_test_unseen,(-1,1))).toarray()\n",
    "print(\"test set unseen ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc;prec;rec;f1;auc;auc-pr\n",
      "0.9116614447925694;0.9153099395589858;0.8233228895851387;0.8339557314200716;0.9999430479827444;0.9997218680658473\n"
     ]
    }
   ],
   "source": [
    "y_pred_score = classifier.predict(test_unseen)\n",
    "\n",
    "y_pred_label = np.around(y_pred_score, 0)\n",
    "\n",
    "report_map = classification_report(y_test_unseen, np.argmax(y_pred_score, axis=1), output_dict=True)\n",
    "\n",
    "#acc_core = accuracy_score(ohe_y_test_unseen, y_pred_label)\n",
    "acc_score = accuracy_score(y_test_unseen, np.argmax(y_pred_score, axis=1))\n",
    "\n",
    "auc_score = roc_auc_score(ohe_y_test_unseen, y_pred_score, multi_class=\"ovr\", average=\"macro\")\n",
    "\n",
    "auc_score_pr = average_precision_score(ohe_y_test_unseen, y_pred_score)\n",
    "\n",
    "result = str(acc_score)+\";\"+str(report_map['macro avg']['precision']) + \";\" + str(\n",
    "        report_map['macro avg']['recall']) + \";\" + str(report_map['macro avg']['f1-score']) + \";\" + str(\n",
    "        auc_score)  + \";\" + str(auc_score_pr)\n",
    "\n",
    "print(\"acc;prec;rec;f1;auc;auc-pr\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15001     0     0]\n",
      " [ 3360  7050  4591]\n",
      " [    0     0 60004]]\n"
     ]
    }
   ],
   "source": [
    "#plot confusion matrix\n",
    "cm = confusion_matrix(y_test_unseen, np.argmax(y_pred_score, axis=1))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0;0.4699686687554163;0.6394267833658338\n",
      "0.9289263874912919;1.0;0.9631537973820015\n"
     ]
    }
   ],
   "source": [
    "report_map = classification_report(y_test_unseen, np.argmax(y_pred_score, axis=1), output_dict=True)\n",
    "result_c1 = str(report_map['1']['precision']) + \";\" + str(\n",
    "        report_map['1']['recall']) + \";\" + str(report_map['1']['f1-score']) \n",
    "\n",
    "result_c2 = str(report_map['2']['precision']) + \";\" + str(\n",
    "        report_map['2']['recall']) + \";\" + str(report_map['2']['f1-score']) \n",
    "print(result_c1)\n",
    "print(result_c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.8170034311856653, 'recall': 1.0, 'f1-score': 0.8992866135123794, 'support': 15001}, '1': {'precision': 1.0, 'recall': 0.4699686687554163, 'f1-score': 0.6394267833658338, 'support': 15001}, '2': {'precision': 0.9289263874912919, 'recall': 1.0, 'f1-score': 0.9631537973820015, 'support': 60004}, 'accuracy': 0.9116614447925694, 'macro avg': {'precision': 0.9153099395589858, 'recall': 0.8233228895851387, 'f1-score': 0.8339557314200716, 'support': 90006}, 'weighted avg': {'precision': 0.9221181635251388, 'recall': 0.9116614447925694, 'f1-score': 0.8985547644010364, 'support': 90006}}\n"
     ]
    }
   ],
   "source": [
    "print(report_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
